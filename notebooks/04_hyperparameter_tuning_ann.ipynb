{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN) \n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  -    The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  -  A common practice is to start with 1–2 hidden layers."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:16:57.449559Z",
     "start_time": "2025-03-28T02:16:54.563396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip uninstall -y scikit-learn\n",
    "# !pip install scikit-learn\n",
    "\n",
    "# !pip uninstall -y scikit-learn\n",
    "!pip install scikit-learn==1.5.1"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.5.1\r\n",
      "  Using cached scikit_learn-1.5.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages (from scikit-learn==1.5.1) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages (from scikit-learn==1.5.1) (1.12.0)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages (from scikit-learn==1.5.1) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.12/site-packages (from scikit-learn==1.5.1) (3.5.0)\r\n",
      "Using cached scikit_learn-1.5.1-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\r\n",
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.6.1\r\n",
      "    Uninstalling scikit-learn-1.6.1:\r\n",
      "      Successfully uninstalled scikit-learn-1.6.1\r\n",
      "Successfully installed scikit-learn-1.5.1\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:01.837650Z",
     "start_time": "2025-03-28T02:16:57.453119Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "\n",
    "sklearn.set_config(display = \"text\")  #This line will suppress the HTML output.\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.001447Z",
     "start_time": "2025-03-28T02:17:01.941439Z"
    }
   },
   "cell_type": "code",
   "source": "from keras import Sequential",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.008077Z",
     "start_time": "2025-03-28T02:17:06.005863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the project's root directory (replace with your actual path)\n",
    "project_root = \"/Users/sunnythesage/PythonProjects/Data-Science-BootCamp/03-Deep-Learning-BootCamp/7 - End to End Deep Learning Project Using ANN/advanced-customer-churn-analysis-using-ann\"\n",
    "\n",
    "# Change the current working directory to the project's root\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Define the artifacts directory path\n",
    "artifacts_dir = os.path.join(os.getcwd(), 'artifacts')\n",
    "\n",
    "# Create the artifacts directory if it doesn't exist\n",
    "os.makedirs(artifacts_dir, exist_ok = True)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.037826Z",
     "start_time": "2025-03-28T02:17:06.012376Z"
    }
   },
   "source": [
    "data = pd.read_csv('data/raw/churn-modelling-dataset.csv')\n",
    "\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis = 1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown = 'ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns = onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis = 1), geo_encoded_df], axis = 1)\n",
    "\n",
    "X = data.drop('Exited', axis = 1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.054672Z",
     "start_time": "2025-03-28T02:17:06.050717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save encoders and scaler for later use\n",
    "\n",
    "# Save encoders and scaler to the artifacts folder\n",
    "with open(os.path.join(artifacts_dir, 'label_encoder_gender.pkl'), 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open(os.path.join(artifacts_dir, 'onehot_encoder_geo.pkl'), 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open(os.path.join(artifacts_dir, 'scaler.pkl'), 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.068198Z",
     "start_time": "2025-03-28T02:17:06.065706Z"
    }
   },
   "source": [
    "from keras.src import layers\n",
    "\n",
    "\n",
    "def create_model(neurons = 32, num_layers = 1, input_dim = None):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Input(shape = (input_dim,)))\n",
    "    model.add(layers.Dense(neurons, activation = 'relu'))\n",
    "\n",
    "    for _ in range(num_layers - 1):\n",
    "        model.add(layers.Dense(neurons, activation = 'relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.087352Z",
     "start_time": "2025-03-28T02:17:06.079104Z"
    }
   },
   "cell_type": "code",
   "source": "from scikeras.wrappers import KerasClassifier",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.101004Z",
     "start_time": "2025-03-28T02:17:06.098653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Patch KerasClassifier to implement __sklearn_tags__\n",
    "def patched_sklearn_tags(self):\n",
    "    return {'estimator_type': 'classifier'}\n",
    "\n",
    "\n",
    "KerasClassifier.__sklearn_tags__ = patched_sklearn_tags"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.114168Z",
     "start_time": "2025-03-28T02:17:06.112132Z"
    }
   },
   "source": [
    "# Create KerasClassifier with explicit parameter mapping\n",
    "model = KerasClassifier(\n",
    "    model = create_model,\n",
    "    model__neurons = 32,\n",
    "    model__num_layers = 1,\n",
    "    model__input_dim = X_train.shape[1],\n",
    "    epochs = 50,\n",
    "    batch_size = 32,\n",
    "    verbose = 1\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.667925Z",
     "start_time": "2025-03-28T02:17:06.125955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check available parameters\n",
    "print(model.get_params().keys())\n",
    "\n",
    "# Test with a single fit first\n",
    "test_model = KerasClassifier(\n",
    "    model = create_model,\n",
    "    model__neurons = 32,\n",
    "    model__num_layers = 1,\n",
    "    model__input_dim = X_train.shape[1],\n",
    "    epochs = 5,\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "sklearn.set_config(display = \"text\")\n",
    "test_model.fit(X_train[:100], y_train[:100])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'model__neurons', 'model__num_layers', 'model__input_dim', 'class_weight'])\n",
      "Epoch 1/5\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - accuracy: 0.4298 - loss: 0.7898  \n",
      "Epoch 2/5\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4484 - loss: 0.7846 \n",
      "Epoch 3/5\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.4649 - loss: 0.7457 \n",
      "Epoch 4/5\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5028 - loss: 0.7418\n",
      "Epoch 5/5\n",
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - accuracy: 0.5547 - loss: 0.6936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=<function create_model at 0x15f921a80>\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=5\n",
       "\tmodel__neurons=32\n",
       "\tmodel__num_layers=1\n",
       "\tmodel__input_dim=12\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T02:17:06.695458Z",
     "start_time": "2025-03-28T02:17:06.693316Z"
    }
   },
   "source": [
    "# Define parameter grid with correct prefixes\n",
    "param_grid = {\n",
    "    'model__neurons': [16, 32, 64],\n",
    "    'model__num_layers': [1, 2],\n",
    "    'model__input_dim': [X_train.shape[1]],  # input_dim is fixed, so it's a list with one element.\n",
    "    'epochs': [50, 100],\n",
    "    'batch_size': [32, 64]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-28T02:17:06.699239Z"
    }
   },
   "source": [
    "# Create and run GridSearchCV\n",
    "grid = GridSearchCV(\n",
    "    estimator = model,\n",
    "    param_grid = param_grid,\n",
    "    cv = 3,\n",
    "    verbose = 1,\n",
    "    n_jobs = 1  # Keras models often don't work well with parallel processing\n",
    ")\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "Epoch 1/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 531us/step - accuracy: 0.5123 - loss: 0.7410\n",
      "Epoch 2/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 468us/step - accuracy: 0.7988 - loss: 0.4724\n",
      "Epoch 3/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 459us/step - accuracy: 0.8122 - loss: 0.4349\n",
      "Epoch 4/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 468us/step - accuracy: 0.8153 - loss: 0.4274\n",
      "Epoch 5/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 459us/step - accuracy: 0.8148 - loss: 0.4273\n",
      "Epoch 6/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 450us/step - accuracy: 0.8324 - loss: 0.4036\n",
      "Epoch 7/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 459us/step - accuracy: 0.8268 - loss: 0.4144\n",
      "Epoch 8/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 468us/step - accuracy: 0.8456 - loss: 0.3821\n",
      "Epoch 9/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - accuracy: 0.8372 - loss: 0.3918\n",
      "Epoch 10/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 523us/step - accuracy: 0.8497 - loss: 0.3759\n",
      "Epoch 11/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 516us/step - accuracy: 0.8491 - loss: 0.3700\n",
      "Epoch 12/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517us/step - accuracy: 0.8438 - loss: 0.3845\n",
      "Epoch 13/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - accuracy: 0.8587 - loss: 0.3556\n",
      "Epoch 14/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - accuracy: 0.8547 - loss: 0.3518\n",
      "Epoch 15/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - accuracy: 0.8548 - loss: 0.3450\n",
      "Epoch 16/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 458us/step - accuracy: 0.8525 - loss: 0.3557\n",
      "Epoch 17/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 451us/step - accuracy: 0.8598 - loss: 0.3433\n",
      "Epoch 18/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 457us/step - accuracy: 0.8555 - loss: 0.3487\n",
      "Epoch 19/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - accuracy: 0.8607 - loss: 0.3364\n",
      "Epoch 20/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - accuracy: 0.8649 - loss: 0.3369\n",
      "Epoch 21/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 465us/step - accuracy: 0.8627 - loss: 0.3397\n",
      "Epoch 22/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 482us/step - accuracy: 0.8537 - loss: 0.3556\n",
      "Epoch 23/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 481us/step - accuracy: 0.8534 - loss: 0.3488\n",
      "Epoch 24/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 526us/step - accuracy: 0.8692 - loss: 0.3318\n",
      "Epoch 25/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step - accuracy: 0.8620 - loss: 0.3381\n",
      "Epoch 26/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 484us/step - accuracy: 0.8606 - loss: 0.3475\n",
      "Epoch 27/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 474us/step - accuracy: 0.8497 - loss: 0.3514\n",
      "Epoch 28/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 474us/step - accuracy: 0.8589 - loss: 0.3404\n",
      "Epoch 29/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 480us/step - accuracy: 0.8568 - loss: 0.3390\n",
      "Epoch 30/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 479us/step - accuracy: 0.8542 - loss: 0.3503\n",
      "Epoch 31/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 541us/step - accuracy: 0.8588 - loss: 0.3419\n",
      "Epoch 32/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 531us/step - accuracy: 0.8539 - loss: 0.3490\n",
      "Epoch 33/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 483us/step - accuracy: 0.8606 - loss: 0.3407\n",
      "Epoch 34/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 509us/step - accuracy: 0.8575 - loss: 0.3424\n",
      "Epoch 35/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 543us/step - accuracy: 0.8592 - loss: 0.3431\n",
      "Epoch 36/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - accuracy: 0.8686 - loss: 0.3294\n",
      "Epoch 37/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 478us/step - accuracy: 0.8654 - loss: 0.3260\n",
      "Epoch 38/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 456us/step - accuracy: 0.8625 - loss: 0.3372\n",
      "Epoch 39/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 451us/step - accuracy: 0.8737 - loss: 0.3214\n",
      "Epoch 40/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 454us/step - accuracy: 0.8632 - loss: 0.3424\n",
      "Epoch 41/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 454us/step - accuracy: 0.8591 - loss: 0.3345\n",
      "Epoch 42/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 485us/step - accuracy: 0.8586 - loss: 0.3527\n",
      "Epoch 43/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 476us/step - accuracy: 0.8569 - loss: 0.3493\n",
      "Epoch 44/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 476us/step - accuracy: 0.8620 - loss: 0.3348\n",
      "Epoch 45/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 456us/step - accuracy: 0.8655 - loss: 0.3310\n",
      "Epoch 46/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 465us/step - accuracy: 0.8588 - loss: 0.3331\n",
      "Epoch 47/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 470us/step - accuracy: 0.8628 - loss: 0.3374\n",
      "Epoch 48/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 535us/step - accuracy: 0.8599 - loss: 0.3409\n",
      "Epoch 49/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 524us/step - accuracy: 0.8626 - loss: 0.3277\n",
      "Epoch 50/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 496us/step - accuracy: 0.8525 - loss: 0.3406\n",
      "\u001B[1m84/84\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 439us/step\n",
      "Epoch 1/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 584us/step - accuracy: 0.6371 - loss: 0.6417\n",
      "Epoch 2/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 527us/step - accuracy: 0.8047 - loss: 0.4783\n",
      "Epoch 3/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 537us/step - accuracy: 0.8153 - loss: 0.4361\n",
      "Epoch 4/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 526us/step - accuracy: 0.8058 - loss: 0.4440\n",
      "Epoch 5/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 533us/step - accuracy: 0.8160 - loss: 0.4309\n",
      "Epoch 6/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 517us/step - accuracy: 0.8256 - loss: 0.4118\n",
      "Epoch 7/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 493us/step - accuracy: 0.8170 - loss: 0.4176\n",
      "Epoch 8/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 480us/step - accuracy: 0.8250 - loss: 0.4123\n",
      "Epoch 9/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 479us/step - accuracy: 0.8233 - loss: 0.4119\n",
      "Epoch 10/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 476us/step - accuracy: 0.8339 - loss: 0.3971\n",
      "Epoch 11/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 462us/step - accuracy: 0.8344 - loss: 0.3972\n",
      "Epoch 12/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 502us/step - accuracy: 0.8287 - loss: 0.3936\n",
      "Epoch 13/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 460us/step - accuracy: 0.8458 - loss: 0.3785\n",
      "Epoch 14/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 508us/step - accuracy: 0.8483 - loss: 0.3751\n",
      "Epoch 15/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 512us/step - accuracy: 0.8529 - loss: 0.3632\n",
      "Epoch 16/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 539us/step - accuracy: 0.8580 - loss: 0.3617\n",
      "Epoch 17/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 519us/step - accuracy: 0.8597 - loss: 0.3551\n",
      "Epoch 18/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 527us/step - accuracy: 0.8627 - loss: 0.3518\n",
      "Epoch 19/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 568us/step - accuracy: 0.8637 - loss: 0.3502\n",
      "Epoch 20/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 566us/step - accuracy: 0.8538 - loss: 0.3561\n",
      "Epoch 21/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 573us/step - accuracy: 0.8646 - loss: 0.3385\n",
      "Epoch 22/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 628us/step - accuracy: 0.8649 - loss: 0.3354\n",
      "Epoch 23/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 547us/step - accuracy: 0.8634 - loss: 0.3399\n",
      "Epoch 24/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 546us/step - accuracy: 0.8643 - loss: 0.3430\n",
      "Epoch 25/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - accuracy: 0.8593 - loss: 0.3424\n",
      "Epoch 26/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 571us/step - accuracy: 0.8610 - loss: 0.3505\n",
      "Epoch 27/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 546us/step - accuracy: 0.8556 - loss: 0.3374\n",
      "Epoch 28/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 563us/step - accuracy: 0.8575 - loss: 0.3491\n",
      "Epoch 29/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - accuracy: 0.8612 - loss: 0.3307\n",
      "Epoch 30/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 534us/step - accuracy: 0.8548 - loss: 0.3483\n",
      "Epoch 31/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 455us/step - accuracy: 0.8592 - loss: 0.3540\n",
      "Epoch 32/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 468us/step - accuracy: 0.8656 - loss: 0.3446\n",
      "Epoch 33/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 461us/step - accuracy: 0.8546 - loss: 0.3435\n",
      "Epoch 34/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 609us/step - accuracy: 0.8685 - loss: 0.3340\n",
      "Epoch 35/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 548us/step - accuracy: 0.8701 - loss: 0.3296\n",
      "Epoch 36/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 460us/step - accuracy: 0.8599 - loss: 0.3407\n",
      "Epoch 37/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 475us/step - accuracy: 0.8664 - loss: 0.3317\n",
      "Epoch 38/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 461us/step - accuracy: 0.8611 - loss: 0.3300\n",
      "Epoch 39/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 524us/step - accuracy: 0.8600 - loss: 0.3424\n",
      "Epoch 40/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 537us/step - accuracy: 0.8643 - loss: 0.3347\n",
      "Epoch 41/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step - accuracy: 0.8669 - loss: 0.3293\n",
      "Epoch 42/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 467us/step - accuracy: 0.8552 - loss: 0.3528\n",
      "Epoch 43/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 468us/step - accuracy: 0.8513 - loss: 0.3539\n",
      "Epoch 44/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 466us/step - accuracy: 0.8604 - loss: 0.3398\n",
      "Epoch 45/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 508us/step - accuracy: 0.8694 - loss: 0.3348\n",
      "Epoch 46/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 473us/step - accuracy: 0.8673 - loss: 0.3278\n",
      "Epoch 47/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 484us/step - accuracy: 0.8662 - loss: 0.3321\n",
      "Epoch 48/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 498us/step - accuracy: 0.8609 - loss: 0.3449\n",
      "Epoch 49/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 454us/step - accuracy: 0.8652 - loss: 0.3346\n",
      "Epoch 50/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 532us/step - accuracy: 0.8700 - loss: 0.3247\n",
      "\u001B[1m84/84\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 425us/step\n",
      "Epoch 1/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 583us/step - accuracy: 0.6330 - loss: 0.6501\n",
      "Epoch 2/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 483us/step - accuracy: 0.7996 - loss: 0.4713\n",
      "Epoch 3/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 520us/step - accuracy: 0.8174 - loss: 0.4307\n",
      "Epoch 4/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 480us/step - accuracy: 0.8035 - loss: 0.4321\n",
      "Epoch 5/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 484us/step - accuracy: 0.8346 - loss: 0.3912\n",
      "Epoch 6/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 512us/step - accuracy: 0.8310 - loss: 0.3906\n",
      "Epoch 7/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 506us/step - accuracy: 0.8448 - loss: 0.3787\n",
      "Epoch 8/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 503us/step - accuracy: 0.8434 - loss: 0.3745\n",
      "Epoch 9/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 536us/step - accuracy: 0.8363 - loss: 0.3822\n",
      "Epoch 10/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 506us/step - accuracy: 0.8592 - loss: 0.3526\n",
      "Epoch 11/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 519us/step - accuracy: 0.8555 - loss: 0.3615\n",
      "Epoch 12/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 487us/step - accuracy: 0.8502 - loss: 0.3595\n",
      "Epoch 13/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 495us/step - accuracy: 0.8615 - loss: 0.3421\n",
      "Epoch 14/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 514us/step - accuracy: 0.8650 - loss: 0.3404\n",
      "Epoch 15/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 491us/step - accuracy: 0.8550 - loss: 0.3465\n",
      "Epoch 16/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 492us/step - accuracy: 0.8587 - loss: 0.3496\n",
      "Epoch 17/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 499us/step - accuracy: 0.8686 - loss: 0.3287\n",
      "Epoch 18/50\n",
      "\u001B[1m167/167\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 473us/step - accuracy: 0.8560 - loss: 0.3413\n",
      "Epoch 19/50\n",
      "\u001B[1m  1/167\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1s\u001B[0m 8ms/step - accuracy: 0.9375 - loss: 0.2110"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
